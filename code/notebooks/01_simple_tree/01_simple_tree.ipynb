{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import sys\n",
    "from time import sleep\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import tqdm\n",
    "sys.path.insert(0, str(pathlib.Path(\"../..\").absolute()))\n",
    "\n",
    "from environment import TreeEnv\n",
    "from computation_sim.system import SystemDrawer\n",
    "from agents.metrics import MovingAverage, MovingTotal\n",
    "from agents.q_agent import DQNActor\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#DEVICE = \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 10\n",
    "params = {\n",
    "    \"environment\" : {\n",
    "        \"num_sensors\": 5,\n",
    "        \"dt\": dt,\n",
    "        \"cost_input\": 0.01,\n",
    "        \"cost_message_loss\": 1.0,\n",
    "        \"cost_output_time\": 0.1 / 100.0,\n",
    "    },\n",
    "    \"actor\" : {\n",
    "        \"learn_period\": int(100 / dt), # Update model every 100ms\n",
    "        \"memory_size\": 2 * 60 * int(1_000 / dt), # Memory spans a period of 2 minutes,\n",
    "        \"tau\" : dt / 2000.0, # Full model update after 2sec\n",
    "        \"batch_size\" : 1024, # Number of samples used in one optimization\n",
    "        \"gamma\": 0.9, # Hyperparam; not really of used in continuous task\n",
    "        \"epsilon_start\": 0.1,\n",
    "        \"epsilon_end\": 0.0,\n",
    "        \"epsilon_decay\" : 4 * 60 * int(1_000 / dt), # Half-life of epsilon decay: 4 minutes\n",
    "        \"lr\" : 1e-3,\n",
    "    },\n",
    "    \"num_sim_steps\": int(3_600_000 / dt) # train for 1h\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82c71a1b1294b7dae662c99d19e8f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'hoverinfo': 'none',\n",
       "              'line': {'color': '#888', 'width': 1.0},\n",
       "              'mode': 'lines',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '0a4358b5-25a6-465f-b4bf-bd5af1288ecb',\n",
       "              'x': [0.4642857142857143, 0.9642857142857143, None,\n",
       "                    0.4642857142857143, 0.9642857142857143, None,\n",
       "                    -0.5357142857142857, -0.035714285714285726, None,\n",
       "                    -0.035714285714285726, 0.4642857142857143, None,\n",
       "                    -0.035714285714285726, 0.4642857142857143, None,\n",
       "                    -0.5357142857142857, -0.035714285714285726, None,\n",
       "                    -0.035714285714285726, 0.4642857142857143, None,\n",
       "                    -0.035714285714285726, 0.4642857142857143, None,\n",
       "                    -0.5357142857142857, -0.035714285714285726, None,\n",
       "                    -0.035714285714285726, 0.4642857142857143, None,\n",
       "                    -0.035714285714285726, 0.4642857142857143, None,\n",
       "                    -0.5357142857142857, -0.035714285714285726, None,\n",
       "                    -0.035714285714285726, 0.4642857142857143, None,\n",
       "                    -0.035714285714285726, 0.4642857142857143, None,\n",
       "                    -0.5357142857142857, -0.035714285714285726, None,\n",
       "                    -0.035714285714285726, 0.4642857142857143, None,\n",
       "                    -0.035714285714285726, 0.4642857142857143, None],\n",
       "              'y': [-0.25, -0.25, None, -0.25, 0.25, None, -1.0, -1.0, None, -1.0,\n",
       "                    -0.25, None, -1.0, 0.25, None, -0.5, -0.5, None, -0.5, -0.25,\n",
       "                    None, -0.5, 0.25, None, 0.0, 0.0, None, 0.0, -0.25, None, 0.0,\n",
       "                    0.25, None, 0.5, 0.5, None, 0.5, -0.25, None, 0.5, 0.25, None,\n",
       "                    1.0, 1.0, None, 1.0, -0.25, None, 1.0, 0.25, None]},\n",
       "             {'hovertext': [is_occupied = 0.0<br>msg.age_oldest =\n",
       "                            0.0<br>msg.age_youngest = 0.0<br>msg.age_average = 0.0,\n",
       "                            num_messages = 0, num_messages = 0, is_busy =\n",
       "                            False<br>t_start_age = 0.0, , is_occupied =\n",
       "                            1.0<br>msg.age_oldest = 0.0<br>msg.age_youngest =\n",
       "                            0.0<br>msg.age_average = 0.0<br>, , is_occupied =\n",
       "                            1.0<br>msg.age_oldest = 0.0<br>msg.age_youngest =\n",
       "                            0.0<br>msg.age_average = 0.0<br>, , is_occupied =\n",
       "                            1.0<br>msg.age_oldest = 0.0<br>msg.age_youngest =\n",
       "                            0.0<br>msg.age_average = 0.0<br>, , is_occupied =\n",
       "                            1.0<br>msg.age_oldest = 0.0<br>msg.age_youngest =\n",
       "                            0.0<br>msg.age_average = 0.0<br>, , is_occupied =\n",
       "                            1.0<br>msg.age_oldest = 0.0<br>msg.age_youngest =\n",
       "                            0.0<br>msg.age_average = 0.0<br>],\n",
       "              'marker': {'color': [floralwhite, darkgrey, darkgrey, darkgreen,\n",
       "                                   floralwhite, darkred, floralwhite, darkred,\n",
       "                                   floralwhite, darkred, floralwhite, darkred,\n",
       "                                   floralwhite, darkred],\n",
       "                         'coloraxis': 'coloraxis',\n",
       "                         'line': {'width': 2},\n",
       "                         'showscale': False,\n",
       "                         'size': 20,\n",
       "                         'symbol': [circle, triangle-down, triangle-down, square,\n",
       "                                    triangle-up, square, triangle-up, square,\n",
       "                                    triangle-up, square, triangle-up, square,\n",
       "                                    triangle-up, square]},\n",
       "              'mode': 'markers+text',\n",
       "              'showlegend': False,\n",
       "              'text': [OUTPUT, LOST_BUFFER, LOST_COMPUTE, COMPUTE, SOURCE_0,\n",
       "                       BUFFER_0, SOURCE_1, BUFFER_1, SOURCE_2, BUFFER_2, SOURCE_3,\n",
       "                       BUFFER_3, SOURCE_4, BUFFER_4],\n",
       "              'textposition': 'top center',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'd024a184-6e60-4f1d-9800-2442b76fab16',\n",
       "              'x': [0.9642857142857143, 0.4642857142857143, 0.9642857142857143,\n",
       "                    0.4642857142857143, -0.5357142857142857, -0.035714285714285726,\n",
       "                    -0.5357142857142857, -0.035714285714285726,\n",
       "                    -0.5357142857142857, -0.035714285714285726,\n",
       "                    -0.5357142857142857, -0.035714285714285726,\n",
       "                    -0.5357142857142857, -0.035714285714285726],\n",
       "              'y': [-0.25, 0.25, 0.25, -0.25, -1.0, -1.0, -0.5, -0.5, 0.0, 0.0,\n",
       "                    0.5, 0.5, 1.0, 1.0]}],\n",
       "    'layout': {'autosize': True,\n",
       "               'coloraxis': {'colorbar': {'thickness': 0, 'ticklen': 0}, 'showscale': False},\n",
       "               'height': 400,\n",
       "               'hovermode': 'closest',\n",
       "               'margin': {'b': 20, 'l': 5, 'r': 5, 't': 40},\n",
       "               'showlegend': False,\n",
       "               'template': '...',\n",
       "               'title': {'font': {'size': 16}},\n",
       "               'width': 400,\n",
       "               'xaxis': {'showgrid': False, 'showticklabels': False, 'zeroline': False},\n",
       "               'yaxis': {'showgrid': False, 'showticklabels': False, 'zeroline': False}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = TreeEnv(**params[\"environment\"])\n",
    "drawer = SystemDrawer()\n",
    "drawer.build(env.system.node_graph)\n",
    "drawer.fw.update_layout(autosize=True, width=400, height=400)\n",
    "clear_output(wait=True)\n",
    "display(drawer.fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DQNActor(num_states=env.observation_space.shape[0], num_actions=env.action_space.n, device=DEVICE, **params[\"actor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    actor: DQNActor,\n",
    "    env: gym.Env,\n",
    "    num_sim_steps: int,\n",
    "    learn_period: int,\n",
    "    num_samples_metrics_filter: int,\n",
    "    num_skip_logging: int = 20,\n",
    "    writer=None,\n",
    "    device: str = \"cpu\",\n",
    "):\n",
    "    # Prepare filters for metrics\n",
    "    avg_message_loss = MovingTotal(num_samples_metrics_filter)\n",
    "    avg_min = MovingAverage(num_samples_metrics_filter)\n",
    "    avg_avg = MovingAverage(num_samples_metrics_filter)\n",
    "    avg_max = MovingAverage(num_samples_metrics_filter)\n",
    "    avg_reward = MovingAverage(num_samples_metrics_filter)\n",
    "\n",
    "    # Initialize the environment\n",
    "    state, _ = env.reset()\n",
    "    state = torch.tensor(state.data, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "    # Run training loop\n",
    "    bar = tqdm.tqdm(range(num_sim_steps))\n",
    "    for i_step in bar:\n",
    "        #bar.set_description(f\"Time: {env.time} ms\")\n",
    "        # Take action, observe transition\n",
    "        action = actor.epsilon_greedy(state)\n",
    "        next_state, reward, _, _, info = env.step(action)\n",
    "\n",
    "        # Push logging\n",
    "        avg_message_loss.push(info[\"total_message_losses\"])\n",
    "        avg_min.push(info[\"last_output_min_age\"])\n",
    "        avg_avg.push(info[\"last_output_avg_age\"])\n",
    "        avg_max.push(info[\"last_output_max_age\"])\n",
    "        avg_reward.push(reward)\n",
    "        if i_step % num_skip_logging == 0:\n",
    "            writer.add_scalar(\"AVG/reward\", avg_reward.value, env.time)\n",
    "            writer.add_scalar(\"AVG/outputMinTime\", avg_min.value, env.time)\n",
    "            writer.add_scalar(\"AVG/outputAvgTime\", avg_avg.value, env.time)\n",
    "            writer.add_scalar(\"AVG/outputMaxTime\", avg_max.value, env.time)\n",
    "            writer.add_scalar(\"AVG/messageLoss\", avg_message_loss.value, env.time)\n",
    "\n",
    "        # Update memory\n",
    "        action = torch.tensor([[action]], device=device, dtype=torch.int64)\n",
    "        next_state = torch.tensor(\n",
    "            next_state.data, dtype=torch.float32, device=device\n",
    "        ).unsqueeze(0)\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        actor.push_memory(state, action, next_state, reward)\n",
    "\n",
    "        # Run learning algo\n",
    "        if i_step % learn_period == 0:\n",
    "            learning_info = actor.optimize_model()\n",
    "\n",
    "        # Log learning stuff\n",
    "        if i_step % num_skip_logging and \"loss\" in learning_info:\n",
    "            writer.add_scalar(\"Learning/Loss\", learning_info[\"loss\"], env.time)\n",
    "        if i_step % num_skip_logging and \"epsilon\" in learning_info:\n",
    "            writer.add_scalar(\"Learning/Epsilon\", learning_info[\"epsilon\"], env.time)\n",
    "\n",
    "        # Close loop\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 119140/360000 [00:56<01:53, 2122.96it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(log_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogs/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_sim_steps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mactor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlearn_period\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5_000\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 53\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(actor, env, num_sim_steps, learn_period, num_samples_metrics_filter, num_skip_logging, writer, device)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Run learning algo\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i_step \u001b[38;5;241m%\u001b[39m learn_period \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 53\u001b[0m     learning_info \u001b[38;5;241m=\u001b[39m \u001b[43mactor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Log learning stuff\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i_step \u001b[38;5;241m%\u001b[39m num_skip_logging \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m learning_info:\n",
      "File \u001b[0;32m~/repos/scheduling/code/notebooks/01_simple_tree/../../agents/q_agent.py:83\u001b[0m, in \u001b[0;36mDQNActor.optimize_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Get samples from memory, prepare for learning\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m transitions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m batch \u001b[38;5;241m=\u001b[39m Sample(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mtransitions))\n\u001b[1;32m     85\u001b[0m state_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(batch\u001b[38;5;241m.\u001b[39ms)\n",
      "File \u001b[0;32m~/repos/scheduling/code/notebooks/01_simple_tree/../../agents/buffer.py:18\u001b[0m, in \u001b[0;36mMemory.sample\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_size):\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/timesync-prototype/lib/python3.10/random.py:502\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k, counts)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m selected:\n\u001b[1;32m    501\u001b[0m             j \u001b[38;5;241m=\u001b[39m randbelow(n)\n\u001b[0;32m--> 502\u001b[0m         \u001b[43mselected_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m         result[i] \u001b[38;5;241m=\u001b[39m population[j]\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(log_dir=\"logs/\")\n",
    "train(\n",
    "    agent,\n",
    "    env,\n",
    "    params[\"num_sim_steps\"],\n",
    "    params[\"actor\"][\"learn_period\"],\n",
    "    int(5_000 / dt),\n",
    "    int(200 / dt),\n",
    "    writer=writer,\n",
    "    device=DEVICE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timesync-prototype",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
